{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dependencies\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ticker List, start date\n",
    "tickers = [\"BTC-USD\", #Bitcoin (deleted - \"ETH-USD\", \"LTC-USD\", \"BITW\", ether, litecoin, top 10 crypto index fund)\n",
    "           \"GLD\", \"SLV\", \"CL=F\", #Gold, silver, crude\n",
    "           \"VIXY\", #VIX Short-Term Futures ETF\n",
    "           \"^IXIC\", \"^GSPC\", \"^DJI\", #Nasdaq, s&p, dow\n",
    "           \"META\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\", \"TSLA\", #faangs, telsa\n",
    "           \"JPM\", \"WFC\", \"C\", \"BAC\", #Big US Banks JPM, WFC, C, BAC\n",
    "           \"UUP\", #usd bull fund\n",
    "           \"IEF\" #iShares 7-10 Year Treasury Bond \n",
    "           ]\n",
    "start_date = \"2013-12-31\"\n",
    "filter_date = \"2014-11-06\" #\"2014-11-06\" - first day BTC tracked on yfinance, \"2018-04-16\" - first day to include entire sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interval lengths, dates\n",
    "long = 50\n",
    "med = 15\n",
    "short = 5\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d').date() - timedelta(days = long)\n",
    "filter_date = datetime.strptime(filter_date, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quantiles, target return\n",
    "quantiles = [.01, .05, .1, .5, .9, .95, .99]\n",
    "model_q = .5\n",
    "#target_return = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "## Look up ticker and create csv\n",
    "for ticker in tickers:\n",
    "    data = pd.DataFrame(yf.download(ticker, start=start_date))\n",
    "    filename = ticker + '.csv'\n",
    "    data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>2023-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>2023-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>2023-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>2023-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date\n",
       "0    2013-11-11\n",
       "1    2013-11-12\n",
       "2    2013-11-13\n",
       "3    2013-11-14\n",
       "4    2013-11-15\n",
       "...         ...\n",
       "3434 2023-04-07\n",
       "3435 2023-04-08\n",
       "3436 2023-04-09\n",
       "3437 2023-04-10\n",
       "3438 2023-04-11\n",
       "\n",
       "[3439 rows x 1 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create comprehensive list of dates\n",
    "#start = datetime.strptime(start_date, '%Y-%m-%d').date() - timedelta(days = long)\n",
    "start = start_date\n",
    "end = date.today() - timedelta(days = 1)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "dates = []\n",
    "while start <= end:\n",
    "    dates.append(start.isoformat())\n",
    "    start += delta\n",
    "\n",
    "dates = pd.DataFrame(dates)\n",
    "dates.columns =['Date']\n",
    "dates['Date'] = pd.to_datetime(dates['Date'])\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create empty pd df for classification analysis\n",
    "df_class = pd.DataFrame(columns=['Ticker', 'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "                                 'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'avgvol_last_1', 'hi_to_lo_last_1'])\n",
    "\n",
    "## Create empty pd df for quantile comparison\n",
    "df_quant = pd.DataFrame(index=quantiles)\n",
    "\n",
    "## Create empty pd df for logistic regression comparison\n",
    "df_logist = pd.DataFrame(columns=['Ticker', 'percentile_' + str(model_q), 'Accuracy', 'TP_rate', 'TN_rate', 'Pos_Predicted_Value', 'Neg_Predicted_Value'])\n",
    "df_logist_profit = pd.DataFrame(columns=['Ticker', 'target_return', 'Accuracy', 'TP_rate', 'TN_rate', 'Pos_Predicted_Value', 'Neg_Predicted_Value'])\n",
    "\n",
    "## Loop thru asset files and add metrics\n",
    "for ticker in tickers:\n",
    "    ## Upload csv datasets\n",
    "    filename = ticker + '.csv'\n",
    "    temp = pd.read_csv(filename)\n",
    "    \n",
    "    ## Format date\n",
    "    temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "    \n",
    "    ## Merge dfs to capture all dates including weekends and market holidays\n",
    "    df = pd.merge(dates, temp, how = 'left', on='Date')\n",
    "    \n",
    "    ## Fill in weekends and market holidays using last trading day\n",
    "    df['Open'].fillna(method='ffill', inplace=True)\n",
    "    df['High'].fillna(method='ffill', inplace=True)\n",
    "    df['Low'].fillna(method='ffill', inplace=True)\n",
    "    df['Close'].fillna(method='ffill', inplace=True)\n",
    "    df['Adj Close'].fillna(method='ffill', inplace=True)\n",
    "    df['Volume'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    ## Shift metrics to get yesterday's value\n",
    "    df['hi_shift'] = df['High'].shift(1)\n",
    "    df['lo_shift'] = df['Low'].shift(1)\n",
    "    df['adjclose_shift'] = df['Adj Close'].shift(1)\n",
    "    df['vol_shift'] = df['Volume'].shift(1)\n",
    "    \n",
    "    ## Calculate 'Adj Close' for past and future\n",
    "    df['close_last_long'] = df['Adj Close'].shift(long)\n",
    "    df['close_last_med'] = df['Adj Close'].shift(med)\n",
    "    df['close_last_short'] = df['Adj Close'].shift(short)\n",
    "    df['close_last_1'] = df['Adj Close'].shift(2)\n",
    "    df['close_next_1'] = df['Adj Close']\n",
    "    df['close_next_short'] = df['Adj Close'].shift(-short + 1)\n",
    "    df['close_next_med'] = df['Adj Close'].shift(-med + 1)\n",
    "    df['close_next_long'] = df['Adj Close'].shift(-long + 1)\n",
    "    \n",
    "    ## Calculate short, med, long hi/lo, avg vol, return\n",
    "    ## Past\n",
    "    df['avgvol_last_long'] = df['vol_shift'].rolling(long).sum() / long\n",
    "    df['vol_hi_lo_last_long'] = (df['vol_shift'].rolling(long).max() / df['vol_shift'].rolling(long).min()) - 1\n",
    "    df['hi_to_lo_last_long'] = (df['adjclose_shift'].rolling(long).max() / df['adjclose_shift'].rolling(long).min()) - 1\n",
    "    df['return_last_long'] = (df['adjclose_shift'] / df['close_last_long']) - 1\n",
    "    df['avgvol_last_med'] = df['vol_shift'].rolling(med).sum() / med\n",
    "    df['vol_hi_lo_last_med'] = (df['vol_shift'].rolling(med).max() / df['vol_shift'].rolling(med).min()) - 1\n",
    "    df['hi_to_lo_last_med'] = (df['adjclose_shift'].rolling(med).max() / df['adjclose_shift'].rolling(med).min()) - 1\n",
    "    df['return_last_med'] = (df['adjclose_shift'] / df['close_last_med']) - 1\n",
    "    df['avgvol_last_short'] = df['vol_shift'].rolling(short).sum() / short\n",
    "    df['vol_hi_lo_last_short'] = (df['vol_shift'].rolling(short).max() / df['vol_shift'].rolling(short).min()) - 1\n",
    "    df['hi_to_lo_last_short'] = (df['adjclose_shift'].rolling(short).max() / df['adjclose_shift'].rolling(short).min()) - 1\n",
    "    df['return_last_short'] = (df['adjclose_shift'] / df['close_last_short']) - 1\n",
    "    df['hi_to_lo_last_1'] = (df['hi_shift'] / df['lo_shift']) - 1\n",
    "    df['return_last_1'] = (df['adjclose_shift'] / df['close_last_1']) - 1\n",
    "    ## Future\n",
    "    df['return_next_1'] = (df['close_next_1'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_short'] = (df['close_next_short'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_med'] = (df['close_next_med'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_long'] = (df['close_next_long'] / df['adjclose_shift']) - 1\n",
    "    \n",
    "    ## Filter out Nulls\n",
    "    df = df.dropna()\n",
    "\n",
    "    ## Find last date in dfs\n",
    "    max_date = df['Date'].max()\n",
    "    \n",
    "    ## Drop unused fields\n",
    "    df = df.drop(columns=['hi_shift', 'lo_shift', 'adjclose_shift',\n",
    "                          'close_last_long', 'close_last_med', 'close_last_short', 'close_last_1', 'close_next_1', 'close_next_long', 'close_next_med', 'close_next_short'])\n",
    "    \n",
    "    ## Rename, add ticker, and rearrange columns\n",
    "    ## Rename\n",
    "    df = df.rename(columns={\"vol_shift\": \"avgvol_last_1\",\n",
    "                            \"avgvol_last_long\": \"avgvol_last_\" + str(long), \n",
    "                            \"vol_hi_lo_last_long\": \"vol_hi_lo_last_\" + str(long),\n",
    "                            \"hi_to_lo_last_long\": \"hi_to_lo_last_\" + str(long),\n",
    "                            \"return_last_long\": \"return_last_\" + str(long),\n",
    "                            \"avgvol_last_med\": \"avgvol_last_\" + str(med), \n",
    "                            \"vol_hi_lo_last_med\": \"vol_hi_lo_last_\" + str(med),\n",
    "                            \"hi_to_lo_last_med\": \"hi_to_lo_last_\" + str(med),\n",
    "                            \"return_last_med\": \"return_last_\" + str(med),\n",
    "                            \"avgvol_last_short\": \"avgvol_last_\" + str(short), \n",
    "                            \"vol_hi_lo_last_short\": \"vol_hi_lo_last_\" + str(short),\n",
    "                            \"hi_to_lo_last_short\": \"hi_to_lo_last_\" + str(short),\n",
    "                            \"return_last_short\": \"return_last_\" + str(short),\n",
    "                            \"return_next_long\": \"return_next_\" + str(long),\n",
    "                            \"return_next_med\": \"return_next_\" + str(med),\n",
    "                            \"return_next_short\": \"return_next_\" + str(short)})\n",
    "    ## Add ticker\n",
    "    df['Ticker'] = ticker\n",
    "\n",
    "    ## Rearrange\n",
    "    df = df[['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', \n",
    "             'avgvol_last_' + str(long), 'vol_hi_lo_last_' + str(long), 'hi_to_lo_last_' + str(long), 'return_last_' + str(long),\n",
    "             'avgvol_last_' + str(med), 'vol_hi_lo_last_' + str(med), 'hi_to_lo_last_' + str(med), 'return_last_' + str(med),\n",
    "             'avgvol_last_' + str(short), 'vol_hi_lo_last_' + str(short), 'hi_to_lo_last_' + str(short), 'return_last_' + str(short),\n",
    "             'avgvol_last_1', 'hi_to_lo_last_1', 'return_last_1',\n",
    "             'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med), 'return_next_' + str(long)]]\n",
    "    \n",
    "    ## Filter dates\n",
    "    df = df.loc[df['Date'] >= pd.to_datetime(filter_date)]\n",
    "\n",
    "    ## Write to individual ticker csv\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    ## df_class\n",
    "    ## Filter df for max_date\n",
    "    df_temp = df.loc[df['Date'] == max_date]\n",
    "    df_temp = df_temp[['Ticker', 'avgvol_last_' + str(long), 'vol_hi_lo_last_' + str(long), 'hi_to_lo_last_' + str(long), \n",
    "                                 'avgvol_last_' + str(med), 'vol_hi_lo_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "                                 'avgvol_last_' + str(short), 'vol_hi_lo_last_' + str(short),  'hi_to_lo_last_' + str(short), \n",
    "                                 'avgvol_last_1', 'hi_to_lo_last_1']]\n",
    "\n",
    "    ## Add row to df_class\n",
    "    df_class = df_class.append(df_temp, ignore_index=True)\n",
    "\n",
    "    ###########################################\n",
    "    \n",
    "    ## df_quant\n",
    "    ## Create df for quantiles of each ticker\n",
    "    df_quant_temp = df[['return_next_' + str(long)]]\n",
    "    df_quant_temp = df_quant_temp.quantile(quantiles)\n",
    "    df_quant_temp = df_quant_temp.rename(columns={'return_next_' + str(long): ticker})\n",
    "\n",
    "    # Merge df with df_blank\n",
    "    df_quant = pd.merge(df_quant, df_quant_temp, left_index=True, right_index=True)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    ## df_logist\n",
    "    ## Get the quantile to use for binary classification\n",
    "    q_model = df_quant.filter(items=[model_q], axis=0).iloc[0][ticker]\n",
    "\n",
    "    ## Add 'Outcome' field \n",
    "    df['Outcome'] = np.where(df['return_next_' + str(long)] >= q_model, 1, 0)\n",
    "\n",
    "    ## Establish y and X variables\n",
    "    y = df['Outcome']\n",
    "    X = df.drop(columns=['Outcome', 'Date', 'Ticker', \n",
    "                         'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
    "                         'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med)])\n",
    "\n",
    "    ## Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=88, stratify=y)\n",
    "\n",
    "    ## Create Logistic Regression Model\n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter=200, random_state=88)\n",
    "\n",
    "    ## Fit model on training data\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    ## Make predictions\n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    ## Calculate confusion matrix, accuracy score, TP_rate, TN_rate\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    TP = cm[0][0]\n",
    "    FN = cm[0][1]\n",
    "    FP = cm[1][0]\n",
    "    TN = cm[1][1]\n",
    "    TP_rate = TP / (TP + FN)\n",
    "    TN_rate = TN / (TN + FP)\n",
    "    PPV_rate = TP / (TP + FP)\n",
    "    NPV_rate = TN / (TN + FN)\n",
    "\n",
    "    ## Append df_logist with each asset score\n",
    "    df_logist_temp = {'Ticker':ticker, 'percentile_' + str(model_q): q_model, 'Accuracy':accuracy, 'TP_rate': TP_rate, 'TN_rate': TN_rate, 'Pos_Predicted_Value': PPV_rate, 'Neg_Predicted_Value': NPV_rate}\n",
    "    df_logist = df_logist.append(df_logist_temp, ignore_index=True)\n",
    "\n",
    "    ###########################################\n",
    "    \n",
    "    # ## df_logist_prof\n",
    "    # ## Add 'Outcome' field \n",
    "    # df['Outcome2'] = np.where(df['return_next_' + str(long)] >= target_return, 1, 0)\n",
    "\n",
    "    # ## Establish y and X variables\n",
    "    # y2 = df['Outcome2']\n",
    "    # X2 = df.drop(columns=['Outcome', 'Outcome2', 'Date', 'Ticker', \n",
    "    #                      'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
    "    #                      'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med)])\n",
    "\n",
    "    # ## Split into train and test\n",
    "    # X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=88, stratify=y2)\n",
    "\n",
    "    # ## Create Logistic Regression Model\n",
    "    # classifier2 = LogisticRegression(solver='lbfgs', max_iter=200, random_state=88)\n",
    "\n",
    "    # ## Fit model on training data\n",
    "    # classifier2.fit(X_train2, y_train2)\n",
    "\n",
    "    # ## Make predictions\n",
    "    # predictions2 = classifier2.predict(X_test2)\n",
    "    \n",
    "    # ## Calculate confusion matrix, accuracy score, TP_rate, TN_rate\n",
    "    # cm2 = confusion_matrix(y_test2, predictions2)\n",
    "    # accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "    # TP2 = cm2[0][0]\n",
    "    # FN2 = cm2[0][1]\n",
    "    # FP2 = cm2[1][0]\n",
    "    # TN2 = cm2[1][1]\n",
    "    # TP_rate2 = TP2 / (TP2 + FN2)\n",
    "    # TN_rate2 = TN2 / (TN2 + FP2)\n",
    "    # PPV_rate2 = TP2 / (TP2 + FP2)\n",
    "    # NPV_rate2 = TN2 / (TN2 + FN2)\n",
    "\n",
    "    # ## Append df_logist with each asset score\n",
    "    # df_logist_temp2 = {'Ticker':ticker, 'target_return': target_return, 'Accuracy':accuracy2, 'TP_rate': TP_rate2, 'TN_rate': TN_rate2, 'Pos_Predicted_Value': PPV_rate2, 'Neg_Predicted_Value': NPV_rate2}\n",
    "    # df_logist_profit = df_logist_profit.append(df_logist_temp2, ignore_index=True)\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "## Write to classification csv\n",
    "df_class.to_csv('df_class.csv')\n",
    "\n",
    "## Write to quantile csv\n",
    "df_quant.to_csv('df_quant.csv')\n",
    "\n",
    "## Write to logistic csv\n",
    "df_logist.to_csv('df_logist.csv')\n",
    "\n",
    "## Write to logistic profit csv\n",
    "# df_logist_profit.to_csv('df_logist_profit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='4762'>\n",
       "  <div class=\"bk-root\" id=\"6701bc9b-46f4-447e-b839-53b7bc3e3106\" data-root-id=\"4762\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"ea52bf5a-2eca-4afb-8a9d-2f45f8ef7131\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"GridStack1\",\"overrides\":[],\"properties\":[{\"default\":\"warn\",\"kind\":null,\"name\":\"mode\"},{\"default\":null,\"kind\":null,\"name\":\"ncols\"},{\"default\":null,\"kind\":null,\"name\":\"nrows\"},{\"default\":true,\"kind\":null,\"name\":\"allow_resize\"},{\"default\":true,\"kind\":null,\"name\":\"allow_drag\"},{\"default\":[],\"kind\":null,\"name\":\"state\"}]},{\"extends\":null,\"module\":null,\"name\":\"click1\",\"overrides\":[],\"properties\":[{\"default\":\"\",\"kind\":null,\"name\":\"terminal_output\"},{\"default\":\"\",\"kind\":null,\"name\":\"debug_name\"},{\"default\":0,\"kind\":null,\"name\":\"clears\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationAreaBase1\",\"overrides\":[],\"properties\":[{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationArea1\",\"overrides\":[],\"properties\":[{\"default\":[],\"kind\":null,\"name\":\"notifications\"},{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"},{\"default\":[{\"background\":\"#ffc107\",\"icon\":{\"className\":\"fas fa-exclamation-triangle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"warning\"},{\"background\":\"#007bff\",\"icon\":{\"className\":\"fas fa-info-circle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"info\"}],\"kind\":null,\"name\":\"types\"}]},{\"extends\":null,\"module\":null,\"name\":\"Notification\",\"overrides\":[],\"properties\":[{\"default\":null,\"kind\":null,\"name\":\"background\"},{\"default\":3000,\"kind\":null,\"name\":\"duration\"},{\"default\":null,\"kind\":null,\"name\":\"icon\"},{\"default\":\"\",\"kind\":null,\"name\":\"message\"},{\"default\":null,\"kind\":null,\"name\":\"notification_type\"},{\"default\":false,\"kind\":null,\"name\":\"_destroyed\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"angle\":{\"value\":0.0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#fc4f30\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"#fc4f30\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"#fc4f30\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"marker\":{\"value\":\"circle\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4848\",\"type\":\"Scatter\"},{\"attributes\":{\"label\":{\"value\":\"2\"},\"renderers\":[{\"id\":\"4855\"}]},\"id\":\"4871\",\"type\":\"LegendItem\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"4873\"},\"glyph\":{\"id\":\"4876\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"4878\"},\"nonselection_glyph\":{\"id\":\"4877\"},\"selection_glyph\":{\"id\":\"4898\"},\"view\":{\"id\":\"4880\"}},\"id\":\"4879\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_color\":{\"value\":\"#e5ae38\"},\"hatch_color\":{\"value\":\"#e5ae38\"},\"line_color\":{\"value\":\"#e5ae38\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4852\",\"type\":\"Scatter\"},{\"attributes\":{\"angle\":{\"value\":0.0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#6d904f\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"#6d904f\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"#6d904f\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"marker\":{\"value\":\"circle\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4898\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#6d904f\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#6d904f\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#6d904f\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4878\",\"type\":\"Scatter\"},{\"attributes\":{\"data\":{\"Assigned_Cluster\":[3,3],\"Ticker\":[\"BTC-USD\",\"TSLA\"],\"hi_to_lo_last_50\":{\"__ndarray__\":\"tpFNLaQW8j/4eja8L6oKQA==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[2]},\"trans_avgvol_last_50\":{\"__ndarray__\":\"TTsVRIb1AkCWmqjfd/vhPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[2]}},\"selected\":{\"id\":\"4874\"},\"selection_policy\":{\"id\":\"4894\"}},\"id\":\"4873\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"4874\",\"type\":\"Selection\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04990\",\"sizing_mode\":\"stretch_width\"},\"id\":\"4915\",\"type\":\"Spacer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#30a2da\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#30a2da\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4811\",\"type\":\"Scatter\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"4812\"},{\"id\":\"4833\"},{\"id\":\"4855\"},{\"id\":\"4879\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Assigned_Cluster\",\"@{Assigned_Cluster}\"],[\"trans_avgvol_last_50\",\"@{trans_avgvol_last_50}\"],[\"hi_to_lo_last_50\",\"@{hi_to_lo_last_50}\"],[\"Ticker\",\"@{Ticker}\"]]},\"id\":\"4766\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"4821\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"4789\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"4784\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"4779\"},\"coordinates\":null,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"4782\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"4804\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_color\":{\"value\":\"#30a2da\"},\"line_color\":{\"value\":\"#30a2da\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4809\",\"type\":\"Scatter\"},{\"attributes\":{\"data\":{\"Assigned_Cluster\":[1],\"Ticker\":[\"IEF\"],\"hi_to_lo_last_50\":{\"__ndarray__\":\"/kpLBxNO678=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[1]},\"trans_avgvol_last_50\":{\"__ndarray__\":\"t0ZZI7eQ578=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[1]}},\"selected\":{\"id\":\"4828\"},\"selection_policy\":{\"id\":\"4844\"}},\"id\":\"4827\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"4828\",\"type\":\"Selection\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Scatter Plot by Asset\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"4771\",\"type\":\"Title\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#e5ae38\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#e5ae38\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#e5ae38\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4853\",\"type\":\"Scatter\"},{\"attributes\":{\"angle\":{\"value\":0.0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#e5ae38\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"#e5ae38\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"#e5ae38\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"marker\":{\"value\":\"circle\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4872\",\"type\":\"Scatter\"},{\"attributes\":{\"label\":{\"value\":\"3\"},\"renderers\":[{\"id\":\"4879\"}]},\"id\":\"4897\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"4777\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"4801\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"4849\"},\"glyph\":{\"id\":\"4852\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"4854\"},\"nonselection_glyph\":{\"id\":\"4853\"},\"selection_glyph\":{\"id\":\"4872\"},\"view\":{\"id\":\"4856\"}},\"id\":\"4855\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis_label\":\"hi_to_lo_last_50\",\"coordinates\":null,\"formatter\":{\"id\":\"4804\"},\"group\":null,\"major_label_policy\":{\"id\":\"4805\"},\"ticker\":{\"id\":\"4784\"}},\"id\":\"4783\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"4827\"}},\"id\":\"4834\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"trans_avgvol_last_50\",\"coordinates\":null,\"formatter\":{\"id\":\"4801\"},\"group\":null,\"major_label_policy\":{\"id\":\"4802\"},\"ticker\":{\"id\":\"4780\"}},\"id\":\"4779\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#6d904f\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#6d904f\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#6d904f\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4877\",\"type\":\"Scatter\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"4806\"},\"glyph\":{\"id\":\"4809\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"4811\"},\"nonselection_glyph\":{\"id\":\"4810\"},\"selection_glyph\":{\"id\":\"4826\"},\"view\":{\"id\":\"4813\"}},\"id\":\"4812\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"4807\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"4783\"},\"coordinates\":null,\"dimension\":1,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"4786\",\"type\":\"Grid\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#fc4f30\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#fc4f30\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#fc4f30\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4832\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_color\":{\"value\":\"#fc4f30\"},\"hatch_color\":{\"value\":\"#fc4f30\"},\"line_color\":{\"value\":\"#fc4f30\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4830\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"4850\",\"type\":\"Selection\"},{\"attributes\":{\"end\":3.7547894260825347,\"reset_end\":3.7547894260825347,\"reset_start\":-1.3054973647421075,\"start\":-1.3054973647421075,\"tags\":[[[\"hi_to_lo_last_50\",\"hi_to_lo_last_50\",null]]]},\"id\":\"4765\",\"type\":\"Range1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#fc4f30\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#fc4f30\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#fc4f30\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4831\",\"type\":\"Scatter\"},{\"attributes\":{\"data\":{\"Assigned_Cluster\":[0,0,0],\"Ticker\":[\"^IXIC\",\"^GSPC\",\"^DJI\"],\"hi_to_lo_last_50\":{\"__ndarray__\":\"ucmfNZBkzb/g/vqBca/jv9v+Z+y6rOu/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]},\"trans_avgvol_last_50\":{\"__ndarray__\":\"jeyL3B7P/D8PCtzbEij7P/VJIyUoM+g/\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[3]}},\"selected\":{\"id\":\"4807\"},\"selection_policy\":{\"id\":\"4821\"}},\"id\":\"4806\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"4849\"}},\"id\":\"4856\",\"type\":\"CDSView\"},{\"attributes\":{\"children\":[{\"id\":\"4763\"},{\"id\":\"4770\"},{\"id\":\"4915\"}],\"margin\":[0,0,0,0],\"name\":\"Row04985\",\"tags\":[\"embedded\"]},\"id\":\"4762\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"4802\",\"type\":\"AllLabels\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"4792\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"angle\":{\"value\":0.0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"#30a2da\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"#30a2da\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"marker\":{\"value\":\"circle\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4826\",\"type\":\"Scatter\"},{\"attributes\":{\"click_policy\":\"mute\",\"coordinates\":null,\"group\":null,\"items\":[{\"id\":\"4825\"},{\"id\":\"4847\"},{\"id\":\"4871\"},{\"id\":\"4897\"}],\"location\":[0,0],\"title\":\"Assigned_Cluster\"},\"id\":\"4824\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"4805\",\"type\":\"AllLabels\"},{\"attributes\":{\"source\":{\"id\":\"4806\"}},\"id\":\"4813\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"4787\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"4788\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"4775\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#30a2da\"},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"value\":\"#30a2da\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#30a2da\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4810\",\"type\":\"Scatter\"},{\"attributes\":{\"label\":{\"value\":\"1\"},\"renderers\":[{\"id\":\"4833\"}]},\"id\":\"4847\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"4780\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"4827\"},\"glyph\":{\"id\":\"4830\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"4832\"},\"nonselection_glyph\":{\"id\":\"4831\"},\"selection_glyph\":{\"id\":\"4848\"},\"view\":{\"id\":\"4834\"}},\"id\":\"4833\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#e5ae38\"},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"value\":\"#e5ae38\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#e5ae38\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4854\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"4868\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"tools\":[{\"id\":\"4766\"},{\"id\":\"4787\"},{\"id\":\"4788\"},{\"id\":\"4789\"},{\"id\":\"4790\"},{\"id\":\"4791\"}]},\"id\":\"4793\",\"type\":\"Toolbar\"},{\"attributes\":{\"source\":{\"id\":\"4873\"}},\"id\":\"4880\",\"type\":\"CDSView\"},{\"attributes\":{\"fill_color\":{\"value\":\"#6d904f\"},\"hatch_color\":{\"value\":\"#6d904f\"},\"line_color\":{\"value\":\"#6d904f\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"trans_avgvol_last_50\"},\"y\":{\"field\":\"hi_to_lo_last_50\"}},\"id\":\"4876\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"4844\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"4894\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"Assigned_Cluster\":[2,2,2,2,2,2,2,2,2,2,2,2,2,2],\"Ticker\":[\"GLD\",\"SLV\",\"CL=F\",\"VIXY\",\"META\",\"AMZN\",\"AAPL\",\"NFLX\",\"GOOG\",\"JPM\",\"WFC\",\"C\",\"BAC\",\"UUP\"],\"hi_to_lo_last_50\":{\"__ndarray__\":\"zukIAmh/57/V8pL2X2Xfv5hTUzJSaOC/4DrWbC2Hzj/Q1l8jGoD5P0o69Bzok+E/TuCnpAZ/pD+Yr0gOP3qsPwak7nlqKrU/gXEq98Up5r8BXXz8mnDOv5vGz6dXZda/mgG+RUXi4b/0AyAyJUjsvw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[14]},\"trans_avgvol_last_50\":{\"__ndarray__\":\"JE30xR3257+4CcuX+2zXv5ueOyvSjv6/45pJMALx57/H/e/hFRu7v+uiOxkpgco/hZdt8hVPyD9DqzhQ01vjv5T99/+La76/ZCZI7WcR4r/g9Lf92lvUv6lEqplshNa/b11M5N3oq7/SaDPpcY7uvw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[14]}},\"selected\":{\"id\":\"4850\"},\"selection_policy\":{\"id\":\"4868\"}},\"id\":\"4849\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"overlay\":{\"id\":\"4792\"}},\"id\":\"4790\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04989\",\"sizing_mode\":\"stretch_width\"},\"id\":\"4763\",\"type\":\"Spacer\"},{\"attributes\":{},\"id\":\"4791\",\"type\":\"ResetTool\"},{\"attributes\":{\"below\":[{\"id\":\"4779\"}],\"center\":[{\"id\":\"4782\"},{\"id\":\"4786\"}],\"height\":300,\"left\":[{\"id\":\"4783\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"4812\"},{\"id\":\"4833\"},{\"id\":\"4855\"},{\"id\":\"4879\"}],\"right\":[{\"id\":\"4824\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"4771\"},\"toolbar\":{\"id\":\"4793\"},\"width\":700,\"x_range\":{\"id\":\"4764\"},\"x_scale\":{\"id\":\"4775\"},\"y_range\":{\"id\":\"4765\"},\"y_scale\":{\"id\":\"4777\"}},\"id\":\"4770\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"end\":2.55330300106573,\"reset_end\":2.55330300106573,\"reset_start\":-2.0932864042530372,\"start\":-2.0932864042530372,\"tags\":[[[\"trans_avgvol_last_50\",\"trans_avgvol_last_50\",null]]]},\"id\":\"4764\",\"type\":\"Range1d\"},{\"attributes\":{\"label\":{\"value\":\"0\"},\"renderers\":[{\"id\":\"4812\"}]},\"id\":\"4825\",\"type\":\"LegendItem\"}],\"root_ids\":[\"4762\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
       "    var render_items = [{\"docid\":\"ea52bf5a-2eca-4afb-8a9d-2f45f8ef7131\",\"root_ids\":[\"4762\"],\"roots\":{\"4762\":\"6701bc9b-46f4-447e-b839-53b7bc3e3106\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Assigned_Cluster]\n",
       "   :Scatter   [trans_avgvol_last_50]   (hi_to_lo_last_50,Ticker)"
      ]
     },
     "execution_count": 427,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "4762"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K-means Classification\n",
    "\n",
    "## Create new variables for log of average volume\n",
    "df_class['trans_avgvol_last_1'] = np.log2(df_class['avgvol_last_1'])\n",
    "df_class['trans_avgvol_last_' + str(short)] = np.log2(df_class['avgvol_last_' + str(short)])\n",
    "df_class['trans_avgvol_last_' + str(med)] = np.log2(df_class['avgvol_last_' + str(med)])\n",
    "df_class['trans_avgvol_last_' + str(long)] = np.log2(df_class['avgvol_last_' + str(long)])\n",
    "\n",
    "## Variable list\n",
    "class_cols = ['trans_avgvol_last_' + str(long), 'vol_hi_lo_last_' + str(long), 'hi_to_lo_last_' + str(long), \n",
    "              'trans_avgvol_last_' + str(med), 'vol_hi_lo_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "              'trans_avgvol_last_' + str(short), 'vol_hi_lo_last_' + str(short), 'hi_to_lo_last_' + str(short), \n",
    "              'trans_avgvol_last_1', 'hi_to_lo_last_1']\n",
    "\n",
    "## Scale the data\n",
    "df_class_scaled = StandardScaler().fit_transform(df_class[class_cols])\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "df_class_scaled = pd.DataFrame(df_class_scaled, columns= class_cols)\n",
    "\n",
    "# Copy the tickers names from the original data\n",
    "df_class_scaled[\"Ticker\"] = df_class[\"Ticker\"]\n",
    "\n",
    "# Set the Ticker column as index\n",
    "df_class_scaled = df_class_scaled.set_index(\"Ticker\")\n",
    "\n",
    "# Initialize the K-Means model with n_clusters\n",
    "model = KMeans(n_clusters=4, random_state=88)\n",
    "\n",
    "# Fit the model for the df_stocks_scaled DataFrame\n",
    "model.fit(df_class_scaled)\n",
    "\n",
    "# Predict the model segments (clusters)\n",
    "asset_clusters = model.predict(df_class_scaled)\n",
    "\n",
    "# Create a new column in the DataFrame with the predicted clusters\n",
    "df_class_scaled[\"Assigned_Cluster\"] = asset_clusters\n",
    "\n",
    "# Create a scatter plot with x=\"AnnualVariance:,  y=\"AnnualReturn\"\n",
    "df_class_scaled.hvplot.scatter(\n",
    "    x='trans_avgvol_last_' + str(long),\n",
    "    y='hi_to_lo_last_' + str(long),\n",
    "    by=\"Assigned_Cluster\",\n",
    "    hover_cols = [\"Ticker\"], \n",
    "    title = \"Scatter Plot by Asset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional features data sources\n",
    "# Consumer Sentiment Data\n",
    "# http://www.sca.isr.umich.edu/tables.html\n",
    "\n",
    "# Gallup polls instituional confidence \n",
    "# https://news.gallup.com/poll/1597/confidence-institutions.aspx \n",
    "\n",
    "# CPI Data\n",
    "# https://www.bls.gov/regions/mid-atlantic/data/consumerpriceindexhistorical_us_table.htm\n",
    "\n",
    "# US GDP\n",
    "# https://www.macrotrends.net/countries/USA/united-states/gdp-gross-domestic-product\n",
    "\n",
    "\n",
    "## Unused #############\n",
    "\n",
    "# Pew polls instituional confidence\n",
    "# https://www.pewresearch.org/politics/2022/06/06/public-trust-in-government-1958-2022/\n",
    "\n",
    "# OECD trust in government\n",
    "# https://data.oecd.org/gga/trust-in-government.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Day  Month  Quarter\n",
       "0    2013-11-11    0     11      4.0\n",
       "1    2013-11-12    1     11      4.0\n",
       "2    2013-11-13    2     11      4.0\n",
       "3    2013-11-14    3     11      4.0\n",
       "4    2013-11-15    4     11      4.0\n",
       "...         ...  ...    ...      ...\n",
       "3434 2023-04-07    4      4      2.0\n",
       "3435 2023-04-08    5      4      2.0\n",
       "3436 2023-04-09    6      4      2.0\n",
       "3437 2023-04-10    0      4      2.0\n",
       "3438 2023-04-11    1      4      2.0\n",
       "\n",
       "[3439 rows x 4 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Date / Time\n",
    "dates2 = dates.copy()\n",
    "dates2['Day'] = pd.to_datetime(dates2['Date']).dt.dayofweek\n",
    "dates2['Month'] = pd.to_datetime(dates2['Date']).dt.month\n",
    "dates2.loc[dates2['Month'] >= 10, 'Quarter'] = 4\n",
    "dates2.loc[dates2['Month'] <= 9, 'Quarter'] = 3\n",
    "dates2.loc[dates2['Month'] <= 6, 'Quarter'] = 2\n",
    "dates2.loc[dates2['Month'] <= 3, 'Quarter'] = 1\n",
    "dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consumer Sentiment Data\n",
    "# http://www.sca.isr.umich.edu/tables.html\n",
    "\n",
    "## Load file\n",
    "csi = pd.read_csv('Resources/tbmics.csv')\n",
    "\n",
    "## Convert month to month number\n",
    "d = {'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\n",
    "csi['Month'] = csi['Month'].map(d)\n",
    "\n",
    "## Create date field, using first day of the month\n",
    "csi['Date'] = pd.to_datetime(dict(year=csi['YYYY'], month=csi['Month'], day=1))\n",
    "\n",
    "## Exclude unnecessary columns\n",
    "csi = csi[['Date', 'ICS_ALL']]\n",
    "\n",
    "## Rename columns\n",
    "csi = csi.rename(columns={\"ICS_ALL\": \"CSI\"})\n",
    "\n",
    "## Merge with date list\n",
    "csi = pd.merge(dates, csi, how = 'left', on='Date')\n",
    "\n",
    "## Interpolate in between readings\n",
    "csi['CSI'].interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gallup Polling Data\n",
    "# https://news.gallup.com/poll/1597/confidence-institutions.aspx\n",
    "\n",
    "## File list\n",
    "polls = ['Resources/gallup_banks.xlsx', 'Resources/gallup_bigbiz.xlsx', 'Resources/gallup_police.xlsx', 'Resources/gallup_pres.xlsx']\n",
    "\n",
    "## Date List\n",
    "gallup = dates\n",
    "\n",
    "for poll in polls:\n",
    "    ## Load file and take first 30 rows\n",
    "    gallup_temp = pd.read_excel(poll)\n",
    "    gallup_temp = gallup_temp.iloc[:30]\n",
    "\n",
    "    ## Create date field, using first day of the month\n",
    "    gallup_temp['Date'] = pd.to_datetime(dict(year=gallup_temp['Year'], month=7, day=1))\n",
    "\n",
    "    ## Exclude unnecessary columns\n",
    "    gallup_temp = gallup_temp[['Date', 'Great deal/Quite a lot']]\n",
    "\n",
    "    ## Rename columns\n",
    "    gallup_temp = gallup_temp.rename(columns={\"Great deal/Quite a lot\": poll[10:len(poll)-5]})\n",
    "\n",
    "    ## Merge with date list\n",
    "    gallup_temp = pd.merge(dates, gallup_temp, how = 'left', on='Date')\n",
    "\n",
    "    ## Interpolate in between readings\n",
    "    gallup_temp[poll[10:len(poll)-5]].interpolate(inplace=True)\n",
    "\n",
    "    ## Merge into gallup df\n",
    "    gallup = pd.merge(gallup, gallup_temp, how = 'left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPI Data\n",
    "# https://www.bls.gov/regions/mid-atlantic/data/consumerpriceindexhistorical_us_table.htm\n",
    "\n",
    "## Load file\n",
    "cpi = pd.read_excel('Resources/cpi.xlsx')\n",
    "\n",
    "## Convert month to month number\n",
    "d = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n",
    "cpi['Month'] = cpi['Month'].map(d)\n",
    "\n",
    "## Create date field, using first day of the month\n",
    "cpi['Date'] = pd.to_datetime(dict(year=cpi['Year'], month=cpi['Month'], day=1))\n",
    "\n",
    "## Exclude unnecessary columns\n",
    "cpi = cpi[['Date', 'CPI']]\n",
    "\n",
    "## Merge with date list\n",
    "cpi = pd.merge(dates, cpi, how = 'left', on='Date')\n",
    "\n",
    "## Interpolate in between readings\n",
    "cpi['CPI'].interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>5.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>5.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>2023-04-09</td>\n",
       "      <td>5.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>5.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>5.9455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     GDP\n",
       "0    2013-11-11     NaN\n",
       "1    2013-11-12     NaN\n",
       "2    2013-11-13     NaN\n",
       "3    2013-11-14     NaN\n",
       "4    2013-11-15     NaN\n",
       "...         ...     ...\n",
       "3434 2023-04-07  5.9455\n",
       "3435 2023-04-08  5.9455\n",
       "3436 2023-04-09  5.9455\n",
       "3437 2023-04-10  5.9455\n",
       "3438 2023-04-11  5.9455\n",
       "\n",
       "[3439 rows x 2 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## US GDP\n",
    "# https://www.macrotrends.net/countries/USA/united-states/gdp-gross-domestic-product\n",
    "\n",
    "## Load file\n",
    "gdp = pd.read_csv('Resources/united-states-gdp-gross-domestic-product.csv')\n",
    "\n",
    "## Convert Date to proper date format\n",
    "gdp['date'] = pd.to_datetime(gdp['date'])\n",
    "\n",
    "## Exclude unnecessary columns\n",
    "gdp = gdp[['date', ' Annual % Change']]\n",
    "\n",
    "## Rename columns\n",
    "gdp = gdp.rename(columns={\"date\": 'Date',\n",
    "                          ' Annual % Change': 'GDP'})\n",
    "\n",
    "## Merge with date list\n",
    "gdp = pd.merge(dates, gdp, how = 'left', on='Date')\n",
    "\n",
    "## Interpolate in between readings\n",
    "gdp['GDP'].interpolate(inplace=True)\n",
    "\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>vader_avg_last_50</th>\n",
       "      <th>vader_avg_last_15</th>\n",
       "      <th>vader_avg_last_5</th>\n",
       "      <th>vader_avg_last_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.082024</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>0.058089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>0.068340</td>\n",
       "      <td>0.085956</td>\n",
       "      <td>0.094568</td>\n",
       "      <td>0.093306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>0.067922</td>\n",
       "      <td>0.084390</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>0.061426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>2023-03-08</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>0.081315</td>\n",
       "      <td>0.062457</td>\n",
       "      <td>0.049406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>2023-03-09</td>\n",
       "      <td>0.065265</td>\n",
       "      <td>0.073648</td>\n",
       "      <td>0.037549</td>\n",
       "      <td>-0.074480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1839 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  vader_avg_last_50  vader_avg_last_15  vader_avg_last_5  \\\n",
       "0    2018-02-25                NaN                NaN               NaN   \n",
       "1    2018-02-26                NaN                NaN               NaN   \n",
       "2    2018-02-27                NaN                NaN               NaN   \n",
       "3    2018-02-28                NaN                NaN               NaN   \n",
       "4    2018-03-01                NaN                NaN               NaN   \n",
       "...         ...                ...                ...               ...   \n",
       "1834 2023-03-05           0.068715           0.082024          0.098283   \n",
       "1835 2023-03-06           0.068340           0.085956          0.094568   \n",
       "1836 2023-03-07           0.067922           0.084390          0.080840   \n",
       "1837 2023-03-08           0.067206           0.081315          0.062457   \n",
       "1838 2023-03-09           0.065265           0.073648          0.037549   \n",
       "\n",
       "      vader_avg_last_1  \n",
       "0                  NaN  \n",
       "1             0.010650  \n",
       "2             0.055795  \n",
       "3            -0.034722  \n",
       "4             0.065192  \n",
       "...                ...  \n",
       "1834          0.058089  \n",
       "1835          0.093306  \n",
       "1836          0.061426  \n",
       "1837          0.049406  \n",
       "1838         -0.074480  \n",
       "\n",
       "[1839 rows x 5 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "## Load file\n",
    "vader = pd.read_csv('../JennS/Sentiments/all_crypto_sentiments.csv')\n",
    "\n",
    "## Convert Date to proper date format\n",
    "vader['Date'] = pd.to_datetime(vader['begins_at'])\n",
    "\n",
    "## Rename columns\n",
    "vader['vader_shift'] = vader['vader_prediction'].shift(1)\n",
    "vader['sentiment_shift'] = vader['sentiment'].shift(1)\n",
    "\n",
    "## Calculate rolling values\n",
    "vader['vader_avg_last_long'] = vader['vader_shift'].rolling(long).sum() / long\n",
    "vader['vader_avg_last_med'] = vader['vader_shift'].rolling(med).sum() / med\n",
    "vader['vader_avg_last_short'] = vader['vader_shift'].rolling(short).sum() / short\n",
    "\n",
    "## Rename columns\n",
    "vader = vader.rename(columns={'vader_shift': 'vader_avg_last_1',\n",
    "                              'vader_avg_last_long': 'vader_avg_last_' + str(long),\n",
    "                              'vader_avg_last_med': 'vader_avg_last_' + str(med),\n",
    "                              'vader_avg_last_short': 'vader_avg_last_' + str(short)})\n",
    "\n",
    "## Exclude unnecessary columns\n",
    "vader = vader[['Date', 'vader_avg_last_' + str(long), 'vader_avg_last_' + str(med), 'vader_avg_last_' + str(short), 'vader_avg_last_1']]\n",
    "\n",
    "vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional data features df (merge all)\n",
    "df_addl = pd.merge(dates, dates2, how='left', on='Date')\n",
    "df_addl = pd.merge(df_addl, csi, how = 'left', on='Date')\n",
    "df_addl = pd.merge(df_addl, gallup, how='left', on='Date')\n",
    "df_addl = pd.merge(df_addl, cpi, how='left', on='Date')\n",
    "df_addl = pd.merge(df_addl, gdp, how='left', on='Date')\n",
    "#df_addl = pd.merge(df_addl, vader, how='left', on='Date')\n",
    "\n",
    "## Filter dates\n",
    "df_addl = df_addl.loc[df_addl['Date'] >= pd.to_datetime(filter_date)]\n",
    "\n",
    "## Write to additional csv\n",
    "df_addl.to_csv('df_addl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[318  61]\n",
      " [286  93]]\n",
      "\n",
      "Accuracy: 54.2%\n",
      "TP_rate: 83.9%\n",
      "TN_rate: 24.5%\n",
      "PPV_rate: 52.6%\n",
      "NPV_rate: 60.4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 1 - Logistic regression - BTC (WITHOUT additional variables / Recreation of original modeling above, just isolating BTC)\n",
    "\n",
    "## Read BTC data\n",
    "df_btc = pd.read_csv('BTC-USD.csv')\n",
    "\n",
    "## Convert 'Date' to date format\n",
    "df_btc['Date'] = pd.to_datetime(df_btc['Date'])\n",
    "\n",
    "## Quantile variable\n",
    "q_model = df_quant.filter(items=[model_q], axis=0).iloc[0]['BTC-USD']\n",
    "\n",
    "## Add 'Outcome' field \n",
    "df_btc['Outcome'] = np.where(df_btc['return_next_' + str(long)] >= q_model, 1, 0)\n",
    "\n",
    "## Establish y and X variables\n",
    "y = df_btc['Outcome']\n",
    "X = df_btc.drop(columns=['Unnamed: 0', 'Outcome', 'Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
    "                         'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med)])\n",
    "\n",
    "## Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=88, \n",
    "                                                    stratify=y)\n",
    "\n",
    "## Create Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=88)\n",
    "\n",
    "## Fit model on training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "## Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
    "\n",
    "## Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "## Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "TP = cm[0][0]\n",
    "FN = cm[0][1]\n",
    "FP = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "TP_rate = TP / (TP + FN)\n",
    "TN_rate = TN / (TN + FP)\n",
    "PPV_rate = TP / (TP + FP)\n",
    "NPV_rate = TN / (TN + FN)\n",
    "\n",
    "print('Confusion Matrix: \\n' + str(cm) + '\\n\\n' + \n",
    "      'Accuracy: ' + str(round(accuracy*100,1)) + '%\\n' +\n",
    "      'TP_rate: ' + str(round(TP_rate*100,1)) + '%\\n' +\n",
    "      'TN_rate: ' + str(round(TN_rate*100,1)) + '%\\n' +\n",
    "      'PPV_rate: ' + str(round(PPV_rate*100,1)) + '%\\n' +\n",
    "      'NPV_rate: ' + str(round(NPV_rate*100,1)) + '%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[318  61]\n",
      " [286  93]]\n",
      "\n",
      "Accuracy: 54.2%\n",
      "TP_rate: 83.9%\n",
      "TN_rate: 24.5%\n",
      "PPV_rate: 52.6%\n",
      "NPV_rate: 60.4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MODEL 2 - Logistic regression - BTC (with additional variables / new start date)\n",
    "## Filter date\n",
    "logistic_filter = filter_date # filter_date = '2014-11-06' - first dat BTC tracked on yfinance, '2018-04-16' - first day of sentiment analysis\n",
    "logistic_filter = pd.to_datetime(logistic_filter)\n",
    "\n",
    "## Read BTC data\n",
    "df_btc = pd.read_csv('BTC-USD.csv')\n",
    "\n",
    "## Convert 'Date' to date format\n",
    "df_btc['Date'] = pd.to_datetime(df_btc['Date'])\n",
    "\n",
    "## Merge with additional variables\n",
    "df_logist_model = pd.merge(df_btc, df_addl, how='left', on='Date')\n",
    "\n",
    "## Filter dates\n",
    "df_logist_model = df_logist_model.loc[df_logist_model['Date'] >= pd.to_datetime(logistic_filter)]\n",
    "\n",
    "## Quantile variable\n",
    "q_model = df_quant.filter(items=[model_q], axis=0).iloc[0]['BTC-USD']\n",
    "\n",
    "## Add 'Outcome' field \n",
    "df_logist_model['Outcome'] = np.where(df_logist_model['return_next_' + str(long)] >= q_model, 1, 0)\n",
    "\n",
    "## Establish y and X variables\n",
    "y = df_logist_model['Outcome']\n",
    "X = df_logist_model.drop(columns=['Unnamed: 0', 'Outcome', 'Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
    "                                  'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med)])\n",
    "\n",
    "## Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=88, \n",
    "                                                    stratify=y)\n",
    "\n",
    "## Create Logistic Regression Model\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=88)\n",
    "\n",
    "## Fit model on training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "## Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "results2 = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
    "\n",
    "## Calculate accuracy score\n",
    "accuracy2 = accuracy_score(y_test, predictions)\n",
    "\n",
    "## Confusion Matrix\n",
    "cm2 = confusion_matrix(y_test, predictions)\n",
    "TP2 = cm2[0][0]\n",
    "FN2 = cm2[0][1]\n",
    "FP2 = cm2[1][0]\n",
    "TN2 = cm2[1][1]\n",
    "TP_rate2 = TP2 / (TP2 + FN2)\n",
    "TN_rate2 = TN2 / (TN2 + FP2)\n",
    "PPV_rate2 = TP2 / (TP2 + FP2)\n",
    "NPV_rate2 = TN2 / (TN2 + FN2)\n",
    "\n",
    "print('Confusion Matrix: \\n' + str(cm2) + '\\n\\n' + \n",
    "      'Accuracy: ' + str(round(accuracy2*100,1)) + '%\\n' +\n",
    "      'TP_rate: ' + str(round(TP_rate2*100,1)) + '%\\n' +\n",
    "      'TN_rate: ' + str(round(TN_rate2*100,1)) + '%\\n' +\n",
    "      'PPV_rate: ' + str(round(PPV_rate2*100,1)) + '%\\n' +\n",
    "      'NPV_rate: ' + str(round(NPV_rate2*100,1)) + '%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>MODEL 1</th>\n",
       "      <th>MODEL 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>54.2</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP_Rate</td>\n",
       "      <td>83.9</td>\n",
       "      <td>83.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN_Rate</td>\n",
       "      <td>24.5</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PPV_Rate</td>\n",
       "      <td>52.6</td>\n",
       "      <td>52.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NPV_Rate</td>\n",
       "      <td>60.4</td>\n",
       "      <td>60.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metric  MODEL 1  MODEL 2\n",
       "0  Accuracy     54.2     54.2\n",
       "1   TP_Rate     83.9     83.9\n",
       "2   TN_Rate     24.5     24.5\n",
       "3  PPV_Rate     52.6     52.6\n",
       "4  NPV_Rate     60.4     60.4"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compare MODEL 1 vs MODEL 2\n",
    "df_compare = pd.DataFrame({'Metric': ['Accuracy', 'TP_Rate', 'TN_Rate', 'PPV_Rate', 'NPV_Rate'],\n",
    "                        'MODEL 1': [round(accuracy*100,1), round(TP_rate*100,1), round(TN_rate*100,1), round(PPV_rate*100,1), round(NPV_rate*100,1)],\n",
    "                        'MODEL 2': [round(accuracy2*100,1), round(TP_rate2*100,1), round(TN_rate2*100,1), round(PPV_rate2*100,1), round(NPV_rate2*100,1)]})\n",
    "\n",
    "df_compare.to_csv('df_compare.csv')\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 3 - Nueral Net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bf4a4e7f6e2b74fd74c37a981ed6c6d83ce25f20bb6a721d0924f01fdba488e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

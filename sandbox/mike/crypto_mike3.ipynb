{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Dependencies\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ticker List, start date\n",
    "tickers = [\"BTC-USD\", \"ETH-USD\", \"BITW\", #Bitcoin, ether, top 10 crypto index fund\n",
    "           \"GLD\", \"SLV\", \"CL=F\", #Gold, silver, crude\n",
    "           \"SVOL\", #Volatility Premium ETF\n",
    "           \"^IXIC\", \"^GSPC\", \"^DJI\", #Nasdaq, s&p, dow\n",
    "           \"META\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\", \"TSLA\", #faangs, telsa\n",
    "           \"XLF\", #financial sector index\n",
    "           \"UUP\", #usd bull fund\n",
    "           \"IEF\" #iShares 7-10 Year Treasury Bond \n",
    "           ]\n",
    "start_date = \"2019-10-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interval lengths\n",
    "long = 30\n",
    "med = 15\n",
    "short = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "## Look up ticker and create csv\n",
    "for ticker in tickers:\n",
    "    data = pd.DataFrame(yf.download(ticker, start=start_date))\n",
    "    filename = ticker + '.csv'\n",
    "    data.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2023-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2023-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2023-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2023-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date\n",
       "0    2019-10-31\n",
       "1    2019-11-01\n",
       "2    2019-11-02\n",
       "3    2019-11-03\n",
       "4    2019-11-04\n",
       "...         ...\n",
       "1251 2023-04-04\n",
       "1252 2023-04-05\n",
       "1253 2023-04-06\n",
       "1254 2023-04-07\n",
       "1255 2023-04-08\n",
       "\n",
       "[1256 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create comprehensive list of dates\n",
    "start = datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "end = date.today() - timedelta(days = 1)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "dates = []\n",
    "while start <= end:\n",
    "    dates.append(start.isoformat())\n",
    "    start += delta\n",
    "\n",
    "dates = pd.DataFrame(dates)\n",
    "dates.columns =['Date']\n",
    "dates['Date'] = pd.to_datetime(dates['Date'])\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create empty pd df for classification analysis\n",
    "df_class = pd.DataFrame(columns=['Ticker', 'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "                                 'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'avgvol_last_1', 'hi_to_lo_last_1'])\n",
    "\n",
    "## Loop thru asset files and add metrics\n",
    "for ticker in tickers:\n",
    "    ## Upload csv datasets\n",
    "    filename = ticker + '.csv'\n",
    "    temp = pd.read_csv(filename)\n",
    "    \n",
    "    ## Format date\n",
    "    temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "    \n",
    "    ## Merge dfs to capture all dates including weekends and market holidays\n",
    "    df = pd.merge(dates, temp, how = 'left', on='Date')\n",
    "    \n",
    "    ## Fill in weekends and market holidays using last trading day\n",
    "    df['Open'].fillna(method='ffill', inplace=True)\n",
    "    df['High'].fillna(method='ffill', inplace=True)\n",
    "    df['Low'].fillna(method='ffill', inplace=True)\n",
    "    df['Close'].fillna(method='ffill', inplace=True)\n",
    "    df['Adj Close'].fillna(method='ffill', inplace=True)\n",
    "    df['Volume'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    ## Shift metrics to get yesterday's value\n",
    "    df['hi_shift'] = df['High'].shift(1)\n",
    "    df['lo_shift'] = df['Low'].shift(1)\n",
    "    df['adjclose_shift'] = df['Adj Close'].shift(1)\n",
    "    df['vol_shift'] = df['Volume'].shift(1)\n",
    "    \n",
    "    ## Calculate 'Adj Close' for past and future\n",
    "    df['close_last_long'] = df['Adj Close'].shift(long)\n",
    "    df['close_last_med'] = df['Adj Close'].shift(med)\n",
    "    df['close_last_short'] = df['Adj Close'].shift(short)\n",
    "    df['close_last_1'] = df['Adj Close'].shift(2)\n",
    "    df['close_next_1'] = df['Adj Close']\n",
    "    df['close_next_short'] = df['Adj Close'].shift(-short + 1)\n",
    "    df['close_next_med'] = df['Adj Close'].shift(-med + 1)\n",
    "    df['close_next_long'] = df['Adj Close'].shift(-long + 1)\n",
    "    \n",
    "    ## Calculate short, med, long hi/lo, avg vol, return\n",
    "    ## Past\n",
    "    df['avgvol_last_long'] = df['vol_shift'].rolling(long).sum() / long\n",
    "    df['hi_to_lo_last_long'] = (df['adjclose_shift'].rolling(long).max() / df['adjclose_shift'].rolling(long).min()) - 1\n",
    "    df['return_last_long'] = (df['adjclose_shift'] / df['close_last_long']) - 1\n",
    "    df['avgvol_last_med'] = df['vol_shift'].rolling(med).sum() / med\n",
    "    df['hi_to_lo_last_med'] = (df['adjclose_shift'].rolling(med).max() / df['adjclose_shift'].rolling(med).min()) - 1\n",
    "    df['return_last_med'] = (df['adjclose_shift'] / df['close_last_med']) - 1\n",
    "    df['avgvol_last_short'] = df['vol_shift'].rolling(short).sum() / short\n",
    "    df['hi_to_lo_last_short'] = (df['adjclose_shift'].rolling(short).max() / df['adjclose_shift'].rolling(short).min()) - 1\n",
    "    df['return_last_short'] = (df['adjclose_shift'] / df['close_last_short']) - 1\n",
    "    df['hi_to_lo_last_1'] = (df['hi_shift'] / df['lo_shift']) - 1\n",
    "    df['return_last_1'] = (df['adjclose_shift'] / df['close_last_1']) - 1\n",
    "    ## Future\n",
    "    df['return_next_1'] = (df['close_next_1'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_short'] = (df['close_next_short'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_med'] = (df['close_next_med'] / df['adjclose_shift']) - 1\n",
    "    df['return_next_long'] = (df['close_next_long'] / df['adjclose_shift']) - 1\n",
    "    \n",
    "    ## Filter out Nulls\n",
    "    df = df.dropna()\n",
    "\n",
    "    ## Find last date in dfs\n",
    "    max_date = df['Date'].max()\n",
    "    \n",
    "    ## Drop unused fields\n",
    "    df = df.drop(columns=['hi_shift', 'lo_shift', 'adjclose_shift',\n",
    "                          'close_last_long', 'close_last_med', 'close_last_short', 'close_last_1', 'close_next_1', 'close_next_long', 'close_next_med', 'close_next_short'])\n",
    "    \n",
    "    ## Rename, add ticker, and rearrange columns\n",
    "    ## Rename\n",
    "    df = df.rename(columns={\"vol_shift\": \"avgvol_last_1\",\n",
    "                            \"avgvol_last_long\": \"avgvol_last_\" + str(long), \n",
    "                            \"hi_to_lo_last_long\": \"hi_to_lo_last_\" + str(long),\n",
    "                            \"return_last_long\": \"return_last_\" + str(long),\n",
    "                            \"avgvol_last_med\": \"avgvol_last_\" + str(med), \n",
    "                            \"hi_to_lo_last_med\": \"hi_to_lo_last_\" + str(med),\n",
    "                            \"return_last_med\": \"return_last_\" + str(med),\n",
    "                            \"avgvol_last_short\": \"avgvol_last_\" + str(short), \n",
    "                            \"hi_to_lo_last_short\": \"hi_to_lo_last_\" + str(short),\n",
    "                            \"return_last_short\": \"return_last_\" + str(short),\n",
    "                            \"return_next_long\": \"return_next_\" + str(long),\n",
    "                            \"return_next_med\": \"return_next_\" + str(med),\n",
    "                            \"return_next_short\": \"return_next_\" + str(short)})\n",
    "    ## Add ticker\n",
    "    df['Ticker'] = ticker\n",
    "\n",
    "    ## Rearrange\n",
    "    df = df[['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', \n",
    "             'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'return_last_' + str(long),\n",
    "             'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med), 'return_last_' + str(med),\n",
    "             'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'return_last_' + str(short),\n",
    "             'avgvol_last_1', 'hi_to_lo_last_1', 'return_last_1',\n",
    "             'return_next_1', 'return_next_' + str(short), 'return_next_' + str(med),'return_next_' + str(long)]]\n",
    "    \n",
    "    ## Write to individual ticker csv\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    ## Filter df for max_date\n",
    "    df_temp = df.loc[df['Date'] == max_date]\n",
    "    df_temp = df_temp[['Ticker', 'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "                       'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'avgvol_last_1', 'hi_to_lo_last_1']]\n",
    "\n",
    "    ## Add row to df_class\n",
    "    df_class = df_class.append(df_temp, ignore_index=True)\n",
    "\n",
    "## Write to classification csv\n",
    "df_class.to_csv('df_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create empty pd df\n",
    "# df_class = pd.DataFrame(columns=['Ticker', 'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "#                                  'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'avgvol_last_1', 'hi_to_lo_last_1'])\n",
    "\n",
    "# ## Find last date in dfs\n",
    "# max_date = df['Date'].max()\n",
    "\n",
    "# ## Filter df for max_date\n",
    "# df_temp = df.loc[df['Date'] == max_date]\n",
    "# df_temp = df_temp[['Ticker', 'avgvol_last_' + str(long), 'hi_to_lo_last_' + str(long), 'avgvol_last_' + str(med), 'hi_to_lo_last_' + str(med),\n",
    "#                      'avgvol_last_' + str(short), 'hi_to_lo_last_' + str(short), 'avgvol_last_1', 'hi_to_lo_last_1']]\n",
    "\n",
    "# ## Add row to df_class\n",
    "# df_class = df_class.append(df_temp, ignore_index=True)\n",
    "# df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional features data sources\n",
    "# http://www.sca.isr.umich.edu/tables.html\n",
    "# https://news.gallup.com/poll/1597/confidence-institutions.aspx\n",
    "# https://www.pewresearch.org/politics/2022/06/06/public-trust-in-government-1958-2022/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bf4a4e7f6e2b74fd74c37a981ed6c6d83ce25f20bb6a721d0924f01fdba488e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
